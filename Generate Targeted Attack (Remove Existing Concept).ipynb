{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb981c07-bda2-4a5a-bb64-78785ed146ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import logging\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"MODELSCOPE_LOG_LEVEL\"] = str(logging.ERROR)\n",
    "torchvision.disable_beta_transforms_warning()\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb841cb-3395-4ac0-9be4-f5366896a936",
   "metadata": {},
   "source": [
    "## Choose Existing Concept to Remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1938fc35-38ac-4b01-b441-9797b9e9499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "captions_dataset = datasets.load_dataset(\n",
    "    \"json\",\n",
    "    data_files = {\"validation\": \"pruned_captions_val2017.json\"},\n",
    "    split = \"validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d09546-7863-4e4f-8008-08ec740f32c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "coco = COCO(\"instances_val2017.json\")\n",
    "\n",
    "assert set(captions_dataset[\"image_id\"]).issubset(set(coco.getImgIds())) # verify if we are querying the correct dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f24842-d7af-4530-9f87-d93d1d1e7343",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "removed_concepts = []\n",
    "concepts_list = []\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "sentence_similarity_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\").to(device)\n",
    "category_embeds = np.asarray([sentence_similarity_model.encode(category[\"name\"]) for category in coco.loadCats(coco.getCatIds())])\n",
    "for prompt in tqdm(captions_dataset[\"caption\"]):\n",
    "    concepts = [\" \".join(word.text for word in phrase if word.pos_ != \"PRON\") for phrase in nlp(prompt).noun_chunks] # remove pronouns\n",
    "    concepts = [concept for concept in concepts if len(concept) > 0]\n",
    "    concept_embeds = np.asarray([sentence_similarity_model.encode(concept) for concept in concepts])\n",
    "    similarity = sentence_similarity_model.similarity(concept_embeds, category_embeds)\n",
    "    removed_concept = concepts[similarity.argmax().detach().item() // len(category_embeds)] # find concept with max similarity to listed categories\n",
    "    \n",
    "    concepts_list.append(concepts)\n",
    "    removed_concepts.append(removed_concept)\n",
    "\n",
    "removed_concepts_dataset = captions_dataset.add_column(\"removed_concept\", removed_concepts)\n",
    "removed_concepts_dataset = removed_concepts_dataset.add_column(\"concepts\", concepts_list)\n",
    "removed_concepts_dataset.to_json(\"pruned_captions_with_removed_concept_val2017.json\")\n",
    "\n",
    "assert removed_concepts_dataset[\"id\"] == captions_dataset[\"id\"] # verify that dataset order is not changed\n",
    "\n",
    "removed_concepts_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c2662-dd6d-42ff-b881-91480a67e549",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_concepts_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bf1a87-806a-4769-9a3d-056ca53917bb",
   "metadata": {},
   "source": [
    "## Initialize Questions for DSG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e71d65-6508-40af-99a9-ac7d02b91661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "removed_concepts_dataset = datasets.load_dataset(\n",
    "    \"json\",\n",
    "    data_files = {\"validation\": \"pruned_captions_with_removed_concept_val2017.json\"},\n",
    "    split = \"validation[:4%]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4164d27-4086-47ba-a6bd-1ca0efc024b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DSG.dsg.query_utils import generate_dsg\n",
    "from DSG.dsg.vqa_utils import MPLUG, calc_vqa_score\n",
    "from DSG.dsg.parse_utils import parse_question_output\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "vqa_model = MPLUG()\n",
    "vqa_model.pipeline_vqa.use_reentrant = False\n",
    "llm_tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-3B\")\n",
    "llm = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.2-3B\", device_map = device, torch_dtype = torch.bfloat16)\n",
    "llm_tokenizer.pad_token = llm_tokenizer.eos_token\n",
    "llm.generation_config.pad_token_id = llm_tokenizer.pad_token_id\n",
    "\n",
    "def autocomplete(prompt, max_new_tokens = 256, **kwargs):\n",
    "    inputs = llm_tokenizer([prompt], return_tensors = \"pt\", padding = True).to(device)\n",
    "    output_ids = llm.generate(**inputs, generation_config = llm.generation_config, max_new_tokens = max_new_tokens, **kwargs)\n",
    "    return llm_tokenizer.batch_decode(output_ids[:, inputs.input_ids.size(dim = 1):])[0].rstrip(llm_tokenizer.eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d363905-9739-412f-ac57-94fe3018a928",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2prompts = {i: {\"input\": caption} for i, caption in enumerate(removed_concepts_dataset[\"removed_concept\"])}\n",
    "\n",
    "_, id2question_outputs, _ = generate_dsg(id2prompts, generate_fn = autocomplete, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc6b9cb-6574-4684-a283-36251cf282d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\"data\": []}\n",
    "for i in tqdm(id2prompts):\n",
    "    image = Image.open(f\"coco_images/{removed_concepts_dataset[i]['image_id']}.jpg\")\n",
    "    qid2question = parse_question_output(id2question_outputs[i][\"output\"])\n",
    "    qid2answer = {qid: vqa_model.vqa(image, question).lower() for qid, question in qid2question.items()}\n",
    "    result[\"data\"].append({\"Removed Concept\": removed_concepts_dataset[i][\"removed_concept\"], \"VQA\": {\"Question\": qid2question, \"Answer\": qid2answer}, \"Score\": calc_vqa_score(qid2answer)[\"average_score_without_dependency\"]})\n",
    "\n",
    "with open(\"eval/coco_removed_concept_dsg.json\", \"w\") as f:\n",
    "    f.write(json.dumps(result))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e14420-6448-4e1b-a5bd-b71992a126ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsg_eval_dataset = datasets.load_dataset(\n",
    "    \"json\",\n",
    "    data_files = {\"eval\": \"eval/coco_removed_concept_dsg.json\"},\n",
    "    split = \"eval\",\n",
    "    field = \"data\"\n",
    ")\n",
    "\n",
    "print(\"Sample Eval -\", dsg_eval_dataset[0])\n",
    "print(\"DSG -\", sum(dsg_eval_dataset[\"Score\"]) / len(dsg_eval_dataset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
